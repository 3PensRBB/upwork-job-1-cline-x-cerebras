... (content for Day 4 slides)
</write_to_file>

Then for Day 5:

<write_to_file>
<path>curriculum/day5-capstone-project/google-slides.md</path>
<content>
... (content for Day 5 slides)
</write_to_file>

Then we can run the git commands.

But note: the user might have a preference for the content of the slides? However, we have been following a pattern, so we'll create them consistently.

Let's generate the content for Day 4 and Day 5 slides.

For Day 4: Real-World AI Applications

We'll follow the same structure as previous days (10 slides).

For Day 5: Capstone Project

Same structure.

After creating these, we'll update the repo.

But note: the user might be satisfied with just the lesson plans? However, the initial request included presentations, and we have provided them for every day so far. So it's expected.

I'll proceed to create the two missing files.
</think>

<write_to_file>
<path>curriculum/day4-real-world-ai-applications/google-slides.md</path>
<content>
# Day 4: Real-World AI Applications - Google Slides Content

## Slide 1: Title Slide
**Title**: AI in Our Schools  
**Subtitle**: Balancing Safety, Privacy, and Learning  
**Visual**: School building with AI icons overlay  
**Notes**:  
- Start with "Where have you seen technology monitoring behavior at school?"  
- Connect to students' personal experiences with school tech

## Slide 2: AI in Education Today
**Content**:  
"Current AI Applications in Schools:  
- Attendance tracking (facial recognition)  
- Proctoring software for exams  
- Personalized learning platforms  
- Safety monitoring systems"  
**Visual**: Collage of real (anonymized) school AI tools  
**Notes**:  
- Keep examples concrete: "Like the cameras in hallways"  
- Ask: "Which of these do you think is most helpful?"

## Slide 3: The Privacy Tradeoff
**Visual**: Scale graphic (Safety vs Privacy)  
**Content**:  
"When AI monitors:  
✓ Can prevent bullying  
✓ May flag neurodivergent students unfairly  
✓ Creates data about your behavior  
✓ Might miss context (standing to stretch vs disruption)"  
**Discussion Prompt**:  
"Where would YOU draw the line for school monitoring?"  
**Notes**:  
- Emphasize there's no perfect answer  
- Reference real cases from ethical dilemmas catalog

## Slide 4: Teachable Machine Introduction
**Visual**: Teachable Machine interface screenshot  
**Content**:  
"Why we're using Teachable Machine:  
✓ No installation needed (works in browser)  
✓ Visual training process  
✓ Immediate feedback  
✓ Perfect for classroom experiments"  
**Demo**:  
Quick tour of image classification workflow  
**Notes**:  
- Highlight "Export Model" feature for future projects

## Slide 5: Classroom Monitor Design
**Interactive Activity**:  
1. Define "appropriate behavior" categories  
2. Collect sample images (synthetic data)  
3. Train model with balanced examples  
**Key Concept**:  
"Garbage in, garbage out: Biased training = biased results"  
**Notes**:  
- Demonstrate with pre-selected classroom scenarios  
- Show how lighting/angles affect recognition

## Slide 6: Activity Instructions
**Teachable Machine Classroom Monitor**  
**Steps**:  
1. Open project at [shortened link]  
2. Train with 30+ examples per category  
3. Test with edge cases (e.g., student standing to answer)  
4. Record false positive/negative rates  
**Data Table Template**:  
| Scenario | Prediction | Correct? |  
|----------|------------|----------|  
| Student raising hand | Appropriate | Yes |  
| Student stretching | Suspicious | No |  
**Notes**:  
- Emphasize using synthetic data only (no real student images)  
- Provide pre-generated training images in resources

## Slide 7: Real-World Case Study
**AI Proctoring Failures**  
**Visual**: Simplified case study graphic  
**Content**:  
- Software flagged students for "suspicious eye movement"  
- Disproportionately affected students with ADHD  
- Caused test anxiety and unfair penalties  
**Discussion Prompt**:  
"How would you redesign this system to be more inclusive?"  
**Notes**:  
- Keep focus on solutions, not just problems  
- Reference ethical dilemmas catalog entry

## Slide 8: Policy Development
**Student Bill of Rights Framework**  
**Visual**: Constitution scroll graphic  
**Content**:  
"Key Rights to Consider:  
- Right to know when AI is monitoring  
- Right to explain unusual behavior  
- Right to human review of AI decisions  
- Right to data deletion after use"  
**Activity**:  
"Draft your top 3 rights for AI in schools"  
**Notes**:  
- Provide sentence starters for drafting  
- Connect to real student advocacy movements

## Slide 9: Reflection Prompt
**Big Question**:  
*"Create a 'Bill of Rights' for students using AI in schools. What 3 rights are most important?"*  
**Visual**: Diverse students holding "rights" signs  
**Notes**:  
- Allow private drafting time first  
- Use "Think-Pair-Share" protocol as described in lesson plan

## Slide 10: Resources & Preview
**For Students**:  
- [Teachable Machine Project Link]  
- [School AI Policy Examples]  
**Preview Day 5**:  
"Tomorrow: Design your own ethical AI solution!"  
**Notes**:  
- Share resources via classroom system  
- Collect exit tickets before dismissal
